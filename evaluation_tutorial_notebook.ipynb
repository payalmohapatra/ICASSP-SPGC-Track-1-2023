{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to verify the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import argparse\n",
    "import math\n",
    "from tqdm import tqdm \n",
    "import random\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as st\n",
    "\n",
    "## Scikit related\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import signal\n",
    "from scipy import integrate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm, kurtosis\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.autograd import Variable\n",
    "# import xgboost as xgb\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "## Torch related\n",
    "## Pytorch related\n",
    "import torch\n",
    "from torch._C import dtype\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available is cuda\n",
      "Shape of x_train_acc (50567, 120, 3)\n",
      "Shape of x_train_gyro (50567, 120, 3)\n",
      "Shape of x_train_hr (50567, 120, 3)\n",
      "Shape of x_train_static (50567, 120, 11)\n",
      "Shape of y_train (50567, 1)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device available is', device)\n",
    "\n",
    "# Update the path to the data files\n",
    "x_train_acc    = np.load('saved_var/x_Train_acc_30_0_3.npy', allow_pickle=True).astype(np.float32)\n",
    "x_train_gyr    = np.load('saved_var/x_Train_gyr_30_0_3.npy', allow_pickle=True).astype(np.float32)\n",
    "x_train_hr     = np.load('saved_var/x_Train_hr_30_0_3.npy', allow_pickle=True).astype(np.float32)\n",
    "x_train_static = np.load('saved_var/x_Train_static_30_0_3.npy', allow_pickle=True).astype(np.float32)\n",
    "y_train        = np.load('saved_var/y_Train_30_0_3.npy', allow_pickle=True).astype(np.float32)\n",
    "y_train        = y_train[:,0]\n",
    "\n",
    "print('Shape of x_train_acc', x_train_acc.shape)\n",
    "print('Shape of x_train_gyro', x_train_gyr.shape)\n",
    "print('Shape of x_train_hr', x_train_hr.shape)\n",
    "print('Shape of x_train_static', x_train_static.shape)\n",
    "print('Shape of y_train', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (conv_acc): Sequential(\n",
      "    (0): Conv1d(3, 8, kernel_size=(3,), stride=(1,), padding=valid)\n",
      "    (1): ReLU()\n",
      "    (2): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=valid)\n",
      "    (3): ReLU()\n",
      "    (4): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=valid)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (conv_gyr): Sequential(\n",
      "    (0): Conv1d(3, 8, kernel_size=(3,), stride=(1,), padding=valid)\n",
      "    (1): ReLU()\n",
      "    (2): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=valid)\n",
      "    (3): ReLU()\n",
      "    (4): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=valid)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (conv_hr): Sequential(\n",
      "    (0): Conv1d(3, 8, kernel_size=(3,), stride=(1,), padding=valid)\n",
      "    (1): ReLU()\n",
      "    (2): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=valid)\n",
      "    (3): ReLU()\n",
      "    (4): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=valid)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (lstm): LSTM(48, 64, batch_first=True)\n",
      "  (nn): Sequential(\n",
      "    (0): Linear(in_features=75, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=46, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 64 \n",
    "hidden_size_fc = 64\n",
    "hidden_size_fc_2 = 64\n",
    "learning_rate = 1e-3\n",
    "num_layers = 1\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_size_fc, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.conv_acc = nn.Sequential(nn.Conv1d(input_size[0], 8, 3, padding='valid'),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv1d(8, 8, 3, padding='valid'),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv1d(8, 16, 3, padding='valid'),\n",
    "                            nn.ReLU(),            \n",
    "                           )  \n",
    "        \n",
    "        self.conv_gyr = nn.Sequential(nn.Conv1d(input_size[1], 8, 3, padding='valid'),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv1d(8, 8, 3, padding='valid'),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv1d(8, 16, 3, padding='valid'),\n",
    "                            nn.ReLU(),            \n",
    "                           )   \n",
    "        \n",
    "        self.conv_hr = nn.Sequential(nn.Conv1d(input_size[2], 8, 3, padding='valid'),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv1d(8, 8, 3, padding='valid'),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Conv1d(8, 16, 3, padding='valid'),\n",
    "                            nn.ReLU(),            \n",
    "                           )\n",
    "                \n",
    "        self.lstm = nn.LSTM(16*3,hidden_size,num_layers,batch_first=True)\n",
    "\n",
    "        self.nn = nn.Sequential(nn.Linear(hidden_size+input_size[3], hidden_size_fc),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(hidden_size_fc, hidden_size_fc_2),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(hidden_size_fc_2, num_classes)       \n",
    "                           )         \n",
    "\n",
    "    \n",
    "    def forward(self, x_acc, x_gyr, x_hr, x_static):\n",
    "        \n",
    "        # conv layers\n",
    "        # print(x_acc.shape)\n",
    "        x_acc = torch.permute(x_acc,(0,2,1))      \n",
    "        x_gyr = torch.permute(x_gyr,(0,2,1))         \n",
    "        x_hr = torch.permute(x_hr,(0,2,1))\n",
    "        out_acc = self.conv_acc(x_acc)\n",
    "        out_gyr = self.conv_gyr(x_gyr)\n",
    "        out_hr = self.conv_hr(x_hr)\n",
    "        out_acc = torch.permute(out_acc,(0,2,1))      \n",
    "        out_gyr = torch.permute(out_gyr,(0,2,1))         \n",
    "        out_hr = torch.permute(out_hr,(0,2,1))\n",
    "        \n",
    "        # concatenate all sensors except static\n",
    "        out = torch.cat((out_acc, out_gyr, out_hr), 2)\n",
    "        \n",
    "        # LSTM        \n",
    "        h0 = Variable(torch.zeros(self.num_layers, out.size(0), hidden_size).to(device))\n",
    "        c0 = Variable(torch.zeros(self.num_layers, out.size(0), hidden_size).to(device))\n",
    "        out, _ = self.lstm(out,(h0,c0))        \n",
    "        # out = out[:, -1, :]\n",
    "        out = torch.mean(out, dim=1)\n",
    "        \n",
    "        # concatenate with static features\n",
    "        out = torch.cat((out, x_static[:,0,:]), 1)\n",
    "        \n",
    "        # nn\n",
    "        out = self.nn(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "input_size = [x_train_acc.shape[2], x_train_gyr.shape[2], x_train_hr.shape[2], x_train_static.shape[2]]\n",
    "num_classes = 46\n",
    "model = LSTM(input_size, hidden_size, hidden_size_fc, num_layers, num_classes).to(device)\n",
    "model = torch.load('saved_var/epoch_2000.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'saved_var/valid_data_1h/' # for valid per day data\n",
    "\n",
    "with torch.no_grad():\n",
    "        actual_user_id = np.zeros((10000,))\n",
    "        predicted_user_id = np.zeros((10000,))        \n",
    "\n",
    "        for count, path in enumerate(os.listdir(folder_path)):\n",
    "            user_id = path.split('_')[3].split('.')[0]\n",
    "            # print(count,user_id)\n",
    "            x_valid = np.load(folder_path+path, allow_pickle=True).astype(np.float32)\n",
    "            x_valid = torch.from_numpy(x_valid).to(torch.float32).to(device)\n",
    "            x_val_acc = x_valid[:,:,[0,1,2]]\n",
    "            x_val_gyr = x_valid[:,:,[3,4,5]]\n",
    "            x_val_hr = x_valid[:,:,[6,7,19]]\n",
    "            x_val_static = x_valid[:,:,8:19]\n",
    "            outputs = model(x_val_acc, x_val_gyr, x_val_hr, x_val_static)\n",
    "            outputs = nn.Softmax(dim=1)(outputs)\n",
    "            outputs = torch.argmax(outputs, dim=1)\n",
    "            outputs = outputs.to('cpu')\n",
    "            # print(st.mode(outputs)[0].item())\n",
    "            actual_user_id[count,] = user_id\n",
    "            predicted_user_id[count,] = st.mode(outputs)[0].item()\n",
    "            \n",
    "        actual_user_id = actual_user_id[0:count+1,]\n",
    "        predicted_user_id = predicted_user_id[0:count+1,]\n",
    "        per_day_val_acc = balanced_accuracy_score(actual_user_id, predicted_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9003111019415367"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_day_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wav2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
